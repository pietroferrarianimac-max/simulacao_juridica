# mvp_simulacao_juridica_avancado.py

import os
import shutil # Para limpar a pasta FAISS se necess√°rio
from dotenv import load_dotenv
from typing import TypedDict, List, Union, Dict, Tuple, Any

# LangChain & LangGraph
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import Docx2txtLoader, DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langgraph.graph import StateGraph, END
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


import streamlit as st

# --- 0. Carregamento de Vari√°veis de Ambiente ---
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    print("Erro: A vari√°vel de ambiente GOOGLE_API_KEY n√£o foi definida.")
    exit()

# --- 1. Constantes e Configura√ß√µes Globais ---
DATA_PATH = "simulacao_juridica_data"
PATH_PROCESSO_EM_SI = os.path.join(DATA_PATH, "processo_em_si")
PATH_MODELOS_PETICOES = os.path.join(DATA_PATH, "modelos_peticoes")
PATH_MODELOS_JUIZ = os.path.join(DATA_PATH, "modelos_juiz")
FAISS_INDEX_PATH = "faiss_index_juridico" # Pasta para salvar o √≠ndice FAISS

# Nomes dos n√≥s do grafo (atores)
ADVOGADO_AUTOR = "advogado_autor"
JUIZ = "juiz"
ADVOGADO_REU = "advogado_reu"

# Etapas Processuais (conforme o rito ordin√°rio do CPC)
ETAPA_PETICAO_INICIAL = "PETICAO_INICIAL"
ETAPA_DESPACHO_RECEBENDO_INICIAL = "DESPACHO_RECEBENDO_INICIAL"
ETAPA_CONTESTACAO = "CONTESTACAO"
ETAPA_DECISAO_SANEAMENTO = "DECISAO_SANEAMENTO"
ETAPA_MANIFESTACAO_SEM_PROVAS_AUTOR = "MANIFESTACAO_SEM_PROVAS_AUTOR"
ETAPA_MANIFESTACAO_SEM_PROVAS_REU = "MANIFESTACAO_SEM_PROVAS_REU"
ETAPA_SENTENCA = "SENTENCA"
ETAPA_FIM_PROCESSO = "_FIM_PROCESSO_" # Etapa final especial

# --- 2. Utilit√°rios RAG ---

def carregar_documentos_docx(caminho_pasta_ou_arquivo: str, tipo_fonte: str, id_processo_especifico: Union[str, None] = None) -> List[Any]:
    documentos = []
    if not os.path.exists(caminho_pasta_ou_arquivo):
        print(f"AVISO RAG: Caminho n√£o encontrado: {caminho_pasta_ou_arquivo}")
        return documentos

    # Carregar um arquivo espec√≠fico de processo (caso atual)
    if tipo_fonte == "processo_atual" and id_processo_especifico and os.path.isfile(caminho_pasta_ou_arquivo):
        if caminho_pasta_ou_arquivo.endswith(".docx"):
            try:
                loader = Docx2txtLoader(caminho_pasta_ou_arquivo)
                docs_carregados = loader.load()
                for doc in docs_carregados:
                    doc.metadata = {"source_type": tipo_fonte, "file_name": os.path.basename(caminho_pasta_ou_arquivo), "process_id": id_processo_especifico}
                documentos.extend(docs_carregados)
                print(f"[RAG] Carregado processo '{os.path.basename(caminho_pasta_ou_arquivo)}' para ID '{id_processo_especifico}'.")
            except Exception as e:
                print(f"Erro ao carregar {caminho_pasta_ou_arquivo}: {e}")
        else:
            print(f"AVISO RAG: Arquivo de processo esperado .docx, encontrado: {caminho_pasta_ou_arquivo}")

    # Carregar todos os .docx de uma pasta (modelos)
    elif tipo_fonte in ["modelo_peticao", "modelo_juiz"] and os.path.isdir(caminho_pasta_ou_arquivo):
        try:
            loader = DirectoryLoader(
                caminho_pasta_ou_arquivo,
                glob="**/*.docx",
                loader_cls=Docx2txtLoader,
                show_progress=False, # Reduzir verbosidade
                use_multithreading=True,
                silent_errors=True
            )
            docs_carregados = loader.load()
            for doc in docs_carregados:
                # Garante que 'source' (nome do arquivo) est√° em 'file_name' para consist√™ncia
                doc.metadata["file_name"] = os.path.basename(doc.metadata.get("source", "unknown.docx"))
                doc.metadata["source_type"] = tipo_fonte
            documentos.extend(docs_carregados)
            print(f"[RAG] Carregados {len(docs_carregados)} documentos da pasta de modelos '{os.path.basename(caminho_pasta_ou_arquivo)}'.")
        except Exception as e:
            print(f"Erro ao carregar modelos de {caminho_pasta_ou_arquivo}: {e}")
            
    return documentos

def criar_ou_carregar_retriever(id_processo: str, arquivo_processo_especifico: str):
    """
    Cria um novo √≠ndice FAISS ou carrega um existente.
    O √≠ndice incluir√° os modelos (comuns a todos os processos) e o arquivo espec√≠fico do processo atual.
    """
    # Limpar √≠ndice antigo para garantir que estamos sempre com os dados mais recentes (opcional)
    # if os.path.exists(FAISS_INDEX_PATH):
    #     print(f"[RAG] Removendo √≠ndice FAISS antigo de '{FAISS_INDEX_PATH}'.")
    #     shutil.rmtree(FAISS_INDEX_PATH)

    embeddings_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001", task_type="retrieval_document")

    if os.path.exists(FAISS_INDEX_PATH):
        try:
            print(f"[RAG] Tentando carregar √≠ndice FAISS existente de '{FAISS_INDEX_PATH}'.")
            vector_store = FAISS.load_local(FAISS_INDEX_PATH, embeddings_model, allow_dangerous_deserialization=True)
            print("[RAG] √çndice FAISS carregado com sucesso.")
            # TODO: Adicionar l√≥gica para verificar se o arquivo_processo_especifico j√° est√° no √≠ndice
            # ou se precisamos adicionar/atualizar apenas esse documento.
            # Por simplicidade neste MVP, se o √≠ndice existe, usamos como est√° ou recriamos.
            # Para uma solu√ß√£o robusta, seria necess√°rio um versionamento ou uma forma de atualizar o √≠ndice.
            # Vamos recriar para garantir que o processo espec√≠fico est√° l√°.
            print("[RAG] Recriando √≠ndice para garantir inclus√£o do processo espec√≠fico e modelos atualizados.")
            if os.path.exists(FAISS_INDEX_PATH): shutil.rmtree(FAISS_INDEX_PATH) # For√ßa recria√ß√£o
            return criar_ou_carregar_retriever(id_processo, arquivo_processo_especifico) # Chama recursivamente para recriar

        except Exception as e:
            print(f"[RAG] Erro ao carregar √≠ndice FAISS: {e}. Recriando...")
            if os.path.exists(FAISS_INDEX_PATH): shutil.rmtree(FAISS_INDEX_PATH) # Limpa se deu erro ao carregar


    print("[RAG] Criando novo √≠ndice FAISS...")
    todos_documentos = []
    # Carrega o arquivo de processo espec√≠fico
    caminho_completo_processo = os.path.join(PATH_PROCESSO_EM_SI, arquivo_processo_especifico)
    todos_documentos.extend(carregar_documentos_docx(caminho_completo_processo, "processo_atual", id_processo_especifico=id_processo))
    
    # Carrega modelos
    todos_documentos.extend(carregar_documentos_docx(PATH_MODELOS_PETICOES, "modelo_peticao"))
    todos_documentos.extend(carregar_documentos_docx(PATH_MODELOS_JUIZ, "modelo_juiz"))

    if not todos_documentos:
        print("ERRO RAG: Nenhum documento foi carregado para o √≠ndice. Verifique as pastas e arquivos .docx.")
        raise ValueError("RAG: Falha ao carregar documentos para o √≠ndice.")

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300) # Chunks maiores para .docx
    docs_divididos = text_splitter.split_documents(todos_documentos)
    
    if not docs_divididos:
        print("ERRO RAG: Nenhum chunk gerado ap√≥s a divis√£o dos documentos.")
        raise ValueError("RAG: Falha ao dividir documentos.")
        
    print(f"[RAG] Documentos divididos em {len(docs_divididos)} chunks.")
    
    try:
        print(f"[RAG] Criando e salvando vector store FAISS em '{FAISS_INDEX_PATH}'.")
        vector_store = FAISS.from_documents(docs_divididos, embeddings_model)
        vector_store.save_local(FAISS_INDEX_PATH)
    except Exception as e:
        print(f"Erro fatal ao criar ou salvar FAISS: {e}")
        raise e

    print("[RAG] Retriever real criado e √≠ndice salvo com sucesso!")
    return vector_store.as_retriever(search_kwargs={'k': 5, 'fetch_k': 10}) # Pega os 5 mais relevantes de 10 buscados

# --- 3. Inicializa√ß√£o do LLM (Modelo Gemini) ---
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0.6, convert_system_message_to_human=True)

# --- 4. Defini√ß√£o do Estado Processual (LangGraph) ---
class EstadoProcessual(TypedDict):
    id_processo: str
    retriever: Any # FAISS retriever instance
    
    # Rastreamento do fluxo
    nome_do_ultimo_no_executado: Union[str, None]
    etapa_concluida_pelo_ultimo_no: Union[str, None]
    proximo_ator_sugerido_pelo_ultimo_no: Union[str, None]
    
    # Informa√ß√£o para o n√≥ atual
    etapa_a_ser_executada_neste_turno: str # Definida pelo router para o n√≥ atual

    # Dados gerados e de contexto
    documento_gerado_na_etapa_recente: Union[str, None] # Pe√ßa/decis√£o gerada na etapa mais recente
    historico_completo: List[Dict[str, str]] # Lista de {"etapa": str, "ator": str, "documento": str}
    
    # Campos espec√≠ficos para certas etapas
    pontos_controvertidos_saneamento: Union[str, None] # Da decis√£o de saneamento
    manifestacao_autor_sem_provas: bool # Flag
    manifestacao_reu_sem_provas: bool # Flag

# --- 5. Mapa de Fluxo Processual (Rito Ordin√°rio) ---
mapa_tarefa_no_atual: Dict[Tuple[Union[str, None], Union[str, None], str], str] = {
    (None, None, ADVOGADO_AUTOR): ETAPA_PETICAO_INICIAL,
    (ADVOGADO_AUTOR, ETAPA_PETICAO_INICIAL, JUIZ): ETAPA_DESPACHO_RECEBENDO_INICIAL,
    (JUIZ, ETAPA_DESPACHO_RECEBENDO_INICIAL, ADVOGADO_REU): ETAPA_CONTESTACAO,
    (ADVOGADO_REU, ETAPA_CONTESTACAO, JUIZ): ETAPA_DECISAO_SANEAMENTO, # Originalmente ia para R√©plica, simplificado para Saneamento
    (JUIZ, ETAPA_DECISAO_SANEAMENTO, ADVOGADO_AUTOR): ETAPA_MANIFESTACAO_SEM_PROVAS_AUTOR,
    (ADVOGADO_AUTOR, ETAPA_MANIFESTACAO_SEM_PROVAS_AUTOR, ADVOGADO_REU): ETAPA_MANIFESTACAO_SEM_PROVAS_REU,
    (ADVOGADO_REU, ETAPA_MANIFESTACAO_SEM_PROVAS_REU, JUIZ): ETAPA_SENTENCA,
}

# --- 6. Fun√ß√£o de Roteamento Condicional (Router) ---
def decidir_proximo_no_do_grafo(estado: EstadoProcessual):
    proximo_ator_sugerido = estado.get("proximo_ator_sugerido_pelo_ultimo_no")
    etapa_concluida = estado.get("etapa_concluida_pelo_ultimo_no")

    print(f"[Router] Estado recebido: { {k: v for k, v in estado.items() if k != 'retriever'} }")
    print(f"[Router] Decidindo pr√≥ximo n√≥. √öltima etapa conclu√≠da: '{etapa_concluida}'. Pr√≥ximo ator sugerido: '{proximo_ator_sugerido}'.")

    if proximo_ator_sugerido == ADVOGADO_AUTOR:
        return ADVOGADO_AUTOR
    elif proximo_ator_sugerido == JUIZ:
        return JUIZ
    elif proximo_ator_sugerido == ADVOGADO_REU:
        return ADVOGADO_REU
    elif proximo_ator_sugerido == ETAPA_FIM_PROCESSO or etapa_concluida == ETAPA_SENTENCA:
        print("[Router] Fluxo direcionado para o FIM.")
        return END
    else:
        print(f"[Router] ERRO: Pr√≥ximo ator '{proximo_ator_sugerido}' desconhecido ou fluxo n√£o previsto. Encerrando.")
        return END

# --- 7. Helpers e Agentes (N√≥s do Grafo) ---

def criar_prompt_e_chain(template_string: str):
    prompt = ChatPromptTemplate.from_template(template_string)
    return prompt | llm | StrOutputParser()

def helper_logica_inicial_no(estado: EstadoProcessual, nome_do_no_atual: str) -> str:
    nome_ultimo_no = estado.get("nome_do_ultimo_no_executado")
    etapa_ultimo_no = estado.get("etapa_concluida_pelo_ultimo_no")
    chave_mapa = (nome_ultimo_no, etapa_ultimo_no, nome_do_no_atual)
    
    if nome_ultimo_no is None and etapa_ultimo_no is None and nome_do_no_atual == ADVOGADO_AUTOR:
        print(f"[{nome_do_no_atual}] Ponto de entrada, definindo etapa como PETICAO_INICIAL.")
        return ETAPA_PETICAO_INICIAL
    
    etapa_designada = mapa_tarefa_no_atual.get(chave_mapa)
    
    if not etapa_designada:
        print(f"ERRO [{nome_do_no_atual}]: N√£o foi poss√≠vel determinar a etapa atual no mapa de tarefas com a chave: {chave_mapa}")
        print(f"Estado atual recebido pelo n√≥: nome_do_ultimo_no_executado='{nome_ultimo_no}', etapa_concluida_pelo_ultimo_no='{etapa_ultimo_no}'")
        return "ERRO_ETAPA_NAO_ENCONTRADA"
        
    print(f"[{nome_do_no_atual}] Iniciando. Etapa designada: {etapa_designada}.")
    return etapa_designada

# (Defini√ß√µes dos agentes ADVOGADO_AUTOR, JUIZ, ADVOGADO_REU - Vers√µes Completas)

def agente_advogado_autor(estado: EstadoProcessual) -> Dict[str, Any]:
    # print(f"[DEBUG ADVOGADO_AUTOR] Etapa atual do n√≥: {estado.get('etapa_a_ser_executada_neste_turno')}") # Redundante com helper
    etapa_atual_do_no = helper_logica_inicial_no(estado, ADVOGADO_AUTOR)
    # estado["etapa_a_ser_executada_neste_turno"] = etapa_atual_do_no # O helper j√° loga isso.

    print(f"\n--- TURNO: {ADVOGADO_AUTOR} (Executando Etapa: {etapa_atual_do_no}) ---")

    if etapa_atual_do_no == "ERRO_ETAPA_NAO_ENCONTRADA":
        print(f"ERRO FATAL: {ADVOGADO_AUTOR} n√£o conseguiu determinar sua etapa. Encerrando fluxo.")
        return {
            "nome_do_ultimo_no_executado": ADVOGADO_AUTOR,
            "etapa_concluida_pelo_ultimo_no": "ERRO_FLUXO_IRRECUPERAVEL",
            "proximo_ator_sugerido_pelo_ultimo_no": ETAPA_FIM_PROCESSO, # Sinaliza fim para o router
            "documento_gerado_na_etapa_recente": "Erro cr√≠tico de fluxo.",
            "historico_completo": estado.get("historico_completo", []) + [{"etapa": "ERRO", "ator": ADVOGADO_AUTOR, "documento": "Erro de fluxo irrecuper√°vel."}],
            "id_processo": estado.get("id_processo", "ID_DESCONHECIDO"), # Preservar estado
            "retriever": estado.get("retriever"),
            "pontos_controvertidos_saneamento": estado.get("pontos_controvertidos_saneamento"),
            "manifestacao_autor_sem_provas": estado.get("manifestacao_autor_sem_provas", False),
            "manifestacao_reu_sem_provas": estado.get("manifestacao_reu_sem_provas", False),
            "etapa_a_ser_executada_neste_turno": "ERRO_FLUXO_IRRECUPERAVEL"
        }

    documento_gerado = f"Documento padr√£o para {ADVOGADO_AUTOR} na etapa {etapa_atual_do_no} n√£o gerado."
    proximo_ator_logico = JUIZ # Default, ser√° sobrescrito pela l√≥gica da etapa
    retriever = estado["retriever"]
    id_processo = estado["id_processo"]
    historico_formatado = "\n".join([f"- Etapa: {item['etapa']}, Ator: {item['ator']}:\n  Documento: {item['documento'][:150]}..." for item in estado.get("historico_completo", [])])
    if not historico_formatado:
        historico_formatado = "Este √© o primeiro ato do processo."

    # --- L√≥gica de RAG para contexto do caso (comum a v√°rias etapas) ---
    query_fatos_caso = f"Resumo dos fatos e principais pontos do processo {id_processo}"
    docs_fatos_caso = retriever.get_relevant_documents(
        query=query_fatos_caso,
        filter={"source_type": "processo_atual", "process_id": id_processo} # Filtra pelo ID do processo!
    )
    contexto_fatos_caso = "\n".join([doc.page_content for doc in docs_fatos_caso]) if docs_fatos_caso else "Nenhum detalhe factual espec√≠fico do caso encontrado no RAG do processo_em_si."
    print(f"[{ADVOGADO_AUTOR}-{etapa_atual_do_no}] Contexto do caso (RAG): {contexto_fatos_caso[:200]}...")

    # --- Tratamento espec√≠fico para cada etapa do Advogado Autor ---
    if etapa_atual_do_no == ETAPA_PETICAO_INICIAL:
        docs_modelo_pi = retriever.get_relevant_documents(query="modelo de peti√ß√£o inicial completa", filter={"source_type": "modelo_peticao"})
        modelo_texto_guia = docs_modelo_pi[0].page_content if docs_modelo_pi else "ERRO RAG: Modelo de peti√ß√£o inicial n√£o encontrado."
        
        template_prompt = """
        Voc√™ √© um Advogado do Autor experiente e est√° elaborando uma Peti√ß√£o Inicial.
        **Processo ID:** {id_processo}
        **Tarefa:** Elaborar a Peti√ß√£o Inicial completa e fundamentada para o caso.

        **Contexto dos Fatos do Caso (extra√≠do do arquivo do processo):**
        {contexto_fatos_caso}

        **Modelo/Guia de Peti√ß√£o Inicial (use como refer√™ncia estrutural e de linguagem jur√≠dica, mas adapte ao caso concreto):**
        {modelo_texto_guia}
        
        **Hist√≥rico Processual at√© o momento:**
        {historico_formatado}
        ---
        Com base em todas as informa√ß√µes acima, redija a Peti√ß√£o Inicial. Seja completo, claro e objetivo.
        Aten√ß√£o aos fatos espec√≠ficos do caso para argumenta√ß√£o.
        N√£o inclua sauda√ß√µes gen√©ricas no in√≠cio ou fim se j√° estiverem no modelo.
        Peti√ß√£o Inicial:
        """
        chain = criar_prompt_e_chain(template_prompt)
        documento_gerado = chain.invoke({
            "id_processo": id_processo,
            "contexto_fatos_caso": contexto_fatos_caso,
            "modelo_texto_guia": modelo_texto_guia,
            "historico_formatado": historico_formatado
        })
        proximo_ator_logico = JUIZ

    elif etapa_atual_do_no == ETAPA_MANIFESTACAO_SEM_PROVAS_AUTOR:
        decisao_saneamento_recebida = estado.get("documento_gerado_na_etapa_recente", "ERRO: Decis√£o de Saneamento n√£o encontrada no estado.")
        pontos_controvertidos = estado.get("pontos_controvertidos_saneamento", "Pontos controvertidos n√£o detalhados.")

        docs_modelo_manifest = retriever.get_relevant_documents(query="modelo de peti√ß√£o ou manifesta√ß√£o declarando n√£o ter mais provas a produzir", filter={"source_type": "modelo_peticao"})
        modelo_texto_guia = docs_modelo_manifest[0].page_content if docs_modelo_manifest else "ERRO RAG: Modelo de manifesta√ß√£o sem provas n√£o encontrado."

        template_prompt = """
        Voc√™ √© o Advogado do Autor. O juiz proferiu Decis√£o de Saneamento e intimou as partes a especificarem provas.
        **Processo ID:** {id_processo}
        **Tarefa:** Elaborar uma peti√ß√£o informando que o Autor n√£o possui mais provas a produzir, requerendo o julgamento do feito no estado em que se encontra, ou protestando por memoriais se for o caso.

        **Contexto dos Fatos do Caso (extra√≠do do arquivo do processo):**
        {contexto_fatos_caso}

        **Decis√£o de Saneamento proferida pelo Juiz:**
        {decisao_saneamento_recebida}
        (Pontos Controvertidos principais: {pontos_controvertidos})
        
        **Modelo/Guia de Manifesta√ß√£o (use como refer√™ncia):**
        {modelo_texto_guia}
        
        **Hist√≥rico Processual at√© o momento:**
        {historico_formatado}
        ---
        Redija a Peti√ß√£o de Manifesta√ß√£o do Autor.
        Manifesta√ß√£o:
        """
        chain = criar_prompt_e_chain(template_prompt)
        documento_gerado = chain.invoke({
            "id_processo": id_processo,
            "contexto_fatos_caso": contexto_fatos_caso,
            "decisao_saneamento_recebida": decisao_saneamento_recebida,
            "pontos_controvertidos": pontos_controvertidos,
            "modelo_texto_guia": modelo_texto_guia,
            "historico_formatado": historico_formatado
        })
        proximo_ator_logico = ADVOGADO_REU # Pr√≥ximo √© o r√©u se manifestar sobre provas

    else:
        print(f"AVISO: L√≥gica para etapa '{etapa_atual_do_no}' do {ADVOGADO_AUTOR} n√£o implementada completamente.")
        documento_gerado = f"Conte√∫do para {ADVOGADO_AUTOR} na etapa {etapa_atual_do_no} n√£o foi gerado pela l√≥gica espec√≠fica."
        proximo_ator_logico = JUIZ # Ou ETAPA_FIM_PROCESSO em caso de erro irrecuper√°vel

    print(f"[{ADVOGADO_AUTOR}-{etapa_atual_do_no}] Documento Gerado (trecho): {documento_gerado[:250]}...")
    
    novo_historico_item = {"etapa": etapa_atual_do_no, "ator": ADVOGADO_AUTOR, "documento": documento_gerado}
    historico_atualizado = estado.get("historico_completo", []) + [novo_historico_item]

    return {
        "nome_do_ultimo_no_executado": ADVOGADO_AUTOR,
        "etapa_concluida_pelo_ultimo_no": etapa_atual_do_no,
        "proximo_ator_sugerido_pelo_ultimo_no": proximo_ator_logico,
        "documento_gerado_na_etapa_recente": documento_gerado,
        "historico_completo": historico_atualizado,
        "pontos_controvertidos_saneamento": estado.get("pontos_controvertidos_saneamento"), # Preserva se j√° existia
        "manifestacao_autor_sem_provas": estado.get("manifestacao_autor_sem_provas", False) or (etapa_atual_do_no == ETAPA_MANIFESTACAO_SEM_PROVAS_AUTOR),
        "manifestacao_reu_sem_provas": estado.get("manifestacao_reu_sem_provas", False),
        "id_processo": estado["id_processo"],
        "retriever": estado["retriever"],
        "etapa_a_ser_executada_neste_turno": etapa_atual_do_no,
    }

def agente_juiz(estado: EstadoProcessual) -> Dict[str, Any]:
    etapa_atual_do_no = helper_logica_inicial_no(estado, JUIZ)
    # estado["etapa_a_ser_executada_neste_turno"] = etapa_atual_do_no # Helper j√° loga

    print(f"\n--- TURNO: {JUIZ} (Executando Etapa: {etapa_atual_do_no}) ---")

    if etapa_atual_do_no == "ERRO_ETAPA_NAO_ENCONTRADA":
        print(f"ERRO FATAL: {JUIZ} n√£o conseguiu determinar sua etapa. Encerrando fluxo.")
        return {
            "nome_do_ultimo_no_executado": JUIZ,
            "etapa_concluida_pelo_ultimo_no": "ERRO_FLUXO_IRRECUPERAVEL",
            "proximo_ator_sugerido_pelo_ultimo_no": ETAPA_FIM_PROCESSO,
            "documento_gerado_na_etapa_recente": "Erro cr√≠tico de fluxo para o Juiz.",
            "historico_completo": estado.get("historico_completo", []) + [{"etapa": "ERRO", "ator": JUIZ, "documento": "Erro de fluxo irrecuper√°vel do Juiz."}],
            "id_processo": estado.get("id_processo", "ID_DESCONHECIDO"), # Preservar estado
            "retriever": estado.get("retriever"),
            "pontos_controvertidos_saneamento": estado.get("pontos_controvertidos_saneamento"),
            "manifestacao_autor_sem_provas": estado.get("manifestacao_autor_sem_provas", False),
            "manifestacao_reu_sem_provas": estado.get("manifestacao_reu_sem_provas", False),
            "etapa_a_ser_executada_neste_turno": "ERRO_FLUXO_IRRECUPERAVEL"
        }

    documento_gerado = f"Decis√£o padr√£o para {JUIZ} na etapa {etapa_atual_do_no} n√£o gerada."
    proximo_ator_logico = ETAPA_FIM_PROCESSO # Default, ser√° sobrescrito
    retriever = estado["retriever"]
    id_processo = estado["id_processo"]
    historico_formatado = "\n".join([f"- Etapa: {item['etapa']}, Ator: {item['ator']}:\n  Documento: {item['documento'][:150]}..." for item in estado.get("historico_completo", [])])
    if not historico_formatado: 
        historico_formatado = "Hist√≥rico processual n√£o dispon√≠vel ou PI ainda n√£o processada."

    documento_da_parte_para_analise = estado.get("documento_gerado_na_etapa_recente", "Nenhuma peti√ß√£o recente das partes para an√°lise.")
    
    query_fatos_caso = f"Resumo dos fatos e principais pontos do processo {id_processo} para decis√£o judicial"
    docs_fatos_caso = retriever.get_relevant_documents(
        query=query_fatos_caso,
        filter={"source_type": "processo_atual", "process_id": id_processo}
    )
    contexto_fatos_caso = "\n".join([doc.page_content for doc in docs_fatos_caso]) if docs_fatos_caso else "Nenhum detalhe factual espec√≠fico do caso encontrado no RAG do processo_em_si."
    print(f"[{JUIZ}-{etapa_atual_do_no}] Contexto do caso (RAG): {contexto_fatos_caso[:200]}...")
    
    pontos_controvertidos_definidos = estado.get("pontos_controvertidos_saneamento") 

    if etapa_atual_do_no == ETAPA_DESPACHO_RECEBENDO_INICIAL:
        docs_modelo_despacho = retriever.get_relevant_documents(query="modelo de despacho judicial recebendo peti√ß√£o inicial e citando o r√©u", filter={"source_type": "modelo_juiz"})
        modelo_texto_guia = docs_modelo_despacho[0].page_content if docs_modelo_despacho else "ERRO RAG: Modelo de despacho inicial n√£o encontrado."

        template_prompt = """
        Voc√™ √© um Juiz de Direito e acaba de receber uma Peti√ß√£o Inicial.
        **Processo ID:** {id_processo}
        **Tarefa:** Analisar a Peti√ß√£o Inicial e proferir um despacho inicial (ex: recebendo a inicial, determinando cita√ß√£o do r√©u, ou outras provid√™ncias preliminares).

        **Contexto dos Fatos do Caso (extra√≠do do arquivo do processo):**
        {contexto_fatos_caso}
        
        **Peti√ß√£o Inicial apresentada pelo Autor:**
        {peticao_inicial}

        **Modelo/Guia de Despacho Inicial (use como refer√™ncia):**
        {modelo_texto_guia}
        
        **Hist√≥rico Processual at√© o momento:**
        {historico_formatado}
        ---
        Com base nisso, redija o Despacho Inicial. Seja claro e objetivo, seguindo a praxe jur√≠dica.
        Despacho Inicial:
        """
        chain = criar_prompt_e_chain(template_prompt)
        documento_gerado = chain.invoke({
            "id_processo": id_processo,
            "contexto_fatos_caso": contexto_fatos_caso,
            "peticao_inicial": documento_da_parte_para_analise,
            "modelo_texto_guia": modelo_texto_guia,
            "historico_formatado": historico_formatado
        })
        proximo_ator_logico = ADVOGADO_REU

    elif etapa_atual_do_no == ETAPA_DECISAO_SANEAMENTO:
        docs_modelo_saneamento = retriever.get_relevant_documents(query="modelo de decis√£o de saneamento e organiza√ß√£o do processo", filter={"source_type": "modelo_juiz"})
        modelo_texto_guia = docs_modelo_saneamento[0].page_content if docs_modelo_saneamento else "ERRO RAG: Modelo de decis√£o de saneamento n√£o encontrado."

        template_prompt = """
        Voc√™ √© um Juiz de Direito e o processo est√° na fase de saneamento, ap√≥s peti√ß√£o inicial e contesta√ß√£o (e eventual r√©plica, que deve ser inferida do hist√≥rico se aplic√°vel).
        **Processo ID:** {id_processo}
        **Tarefa:** Proferir uma Decis√£o de Saneamento e Organiza√ß√£o do Processo. Defina as quest√µes processuais pendentes, as quest√µes de fato sobre as quais recair√° a atividade probat√≥ria (pontos controvertidos), distribua o √¥nus da prova e, se for o caso, designe audi√™ncia ou determine as provas a serem produzidas.

        **Contexto dos Fatos do Caso (extra√≠do do arquivo do processo):**
        {contexto_fatos_caso}
        
        **√öltima manifesta√ß√£o relevante das partes (ex: Contesta√ß√£o do R√©u ou R√©plica do Autor):**
        {ultima_peticao_partes}

        **Modelo/Guia de Decis√£o de Saneamento (use como refer√™ncia):**
        {modelo_texto_guia}
        
        **Hist√≥rico Processual Completo (incluindo PI, Contesta√ß√£o, etc.):**
        {historico_formatado}
        ---
        Com base nisso, redija a Decis√£o de Saneamento.
        Inclua uma se√ß√£o clara definindo os PONTOS CONTROVERTIDOS. Ex: "PONTOS CONTROVERTIDOS: 1. A exist√™ncia do contrato; 2. O alegado inadimplemento."
        Decis√£o de Saneamento:
        """
        chain = criar_prompt_e_chain(template_prompt)
        documento_gerado = chain.invoke({
            "id_processo": id_processo,
            "contexto_fatos_caso": contexto_fatos_caso,
            "ultima_peticao_partes": documento_da_parte_para_analise, # Esta √© a contesta√ß√£o do r√©u
            "modelo_texto_guia": modelo_texto_guia,
            "historico_formatado": historico_formatado
        })
        proximo_ator_logico = ADVOGADO_AUTOR 
        
        try:
            inicio_pc = documento_gerado.upper().find("PONTOS CONTROVERTIDOS:")
            if inicio_pc != -1:
                fim_pc = documento_gerado.find("\n\n", inicio_pc) 
                if fim_pc == -1: fim_pc = len(documento_gerado)
                pontos_controvertidos_definidos = documento_gerado[inicio_pc + len("PONTOS CONTROVERTIDOS:"):fim_pc].strip()
            else:
                pontos_controvertidos_definidos = "N√£o foi poss√≠vel extrair os pontos controvertidos automaticamente. Verificar decis√£o."
        except Exception:
            pontos_controvertidos_definidos = "Erro ao tentar extrair pontos controvertidos."
        print(f"[{JUIZ}-{etapa_atual_do_no}] Pontos Controvertidos extra√≠dos/definidos: {pontos_controvertidos_definidos}")

    elif etapa_atual_do_no == ETAPA_SENTENCA:
        docs_modelo_sentenca = retriever.get_relevant_documents(query="modelo de senten√ßa judicial c√≠vel", filter={"source_type": "modelo_juiz"})
        modelo_texto_guia = docs_modelo_sentenca[0].page_content if docs_modelo_sentenca else "ERRO RAG: Modelo de senten√ßa n√£o encontrado."

        template_prompt = """
        Voc√™ √© um Juiz de Direito e o processo est√° concluso para senten√ßa, ap√≥s as partes indicarem n√£o ter mais provas a produzir.
        **Processo ID:** {id_processo}
        **Tarefa:** Analisar todo o processo (fatos, argumentos das partes, provas constantes nos autos - simuladas pelo hist√≥rico) e proferir a Senten√ßa.

        **Contexto dos Fatos do Caso (extra√≠do do arquivo do processo):**
        {contexto_fatos_caso}
        
        **√öltima manifesta√ß√£o relevante das partes (ex: R√©u indicando n√£o ter provas):**
        {ultima_peticao_partes}

        **Pontos Controvertidos definidos no Saneamento:**
        {pontos_controvertidos_saneamento}

        **Modelo/Guia de Senten√ßa (use como refer√™ncia para estrutura: relat√≥rio, fundamenta√ß√£o, dispositivo):**
        {modelo_texto_guia}
        
        **Hist√≥rico Processual Completo (incluindo PI, Contesta√ß√£o, R√©plica, Saneamento, Manifesta√ß√µes sobre provas):**
        {historico_formatado}
        ---
        Com base em todas as informa√ß√µes e no seu conhecimento jur√≠dico, redija a Senten√ßa completa.
        Senten√ßa:
        """
        chain = criar_prompt_e_chain(template_prompt)
        documento_gerado = chain.invoke({
            "id_processo": id_processo,
            "contexto_fatos_caso": contexto_fatos_caso,
            "ultima_peticao_partes": documento_da_parte_para_analise,
            "pontos_controvertidos_saneamento": estado.get("pontos_controvertidos_saneamento", "N√£o definidos anteriormente."),
            "modelo_texto_guia": modelo_texto_guia,
            "historico_formatado": historico_formatado
        })
        proximo_ator_logico = ETAPA_FIM_PROCESSO

    else:
        print(f"AVISO: L√≥gica para etapa '{etapa_atual_do_no}' do {JUIZ} n√£o implementada completamente.")
        documento_gerado = f"Conte√∫do para {JUIZ} na etapa {etapa_atual_do_no} n√£o foi gerado pela l√≥gica espec√≠fica."
        proximo_ator_logico = ETAPA_FIM_PROCESSO 

    print(f"[{JUIZ}-{etapa_atual_do_no}] Documento Gerado (trecho): {documento_gerado[:250]}...")

    novo_historico_item = {"etapa": etapa_atual_do_no, "ator": JUIZ, "documento": documento_gerado}
    historico_atualizado = estado.get("historico_completo", []) + [novo_historico_item]
    
    return {
        "nome_do_ultimo_no_executado": JUIZ,
        "etapa_concluida_pelo_ultimo_no": etapa_atual_do_no,
        "proximo_ator_sugerido_pelo_ultimo_no": proximo_ator_logico,
        "documento_gerado_na_etapa_recente": documento_gerado,
        "historico_completo": historico_atualizado,
        "pontos_controvertidos_saneamento": pontos_controvertidos_definidos,
        "manifestacao_autor_sem_provas": estado.get("manifestacao_autor_sem_provas", False), 
        "manifestacao_reu_sem_provas": estado.get("manifestacao_reu_sem_provas", False),   
        "id_processo": estado["id_processo"],
        "retriever": estado["retriever"],
        "etapa_a_ser_executada_neste_turno": etapa_atual_do_no,
    }

def agente_advogado_reu(estado: EstadoProcessual) -> Dict[str, Any]:
    etapa_atual_do_no = helper_logica_inicial_no(estado, ADVOGADO_REU)
    # estado["etapa_a_ser_executada_neste_turno"] = etapa_atual_do_no # Helper j√° loga

    print(f"\n--- TURNO: {ADVOGADO_REU} (Executando Etapa: {etapa_atual_do_no}) ---")

    if etapa_atual_do_no == "ERRO_ETAPA_NAO_ENCONTRADA":
        print(f"ERRO FATAL: {ADVOGADO_REU} n√£o conseguiu determinar sua etapa. Encerrando fluxo.")
        return {
            "nome_do_ultimo_no_executado": ADVOGADO_REU,
            "etapa_concluida_pelo_ultimo_no": "ERRO_FLUXO_IRRECUPERAVEL",
            "proximo_ator_sugerido_pelo_ultimo_no": ETAPA_FIM_PROCESSO,
            "documento_gerado_na_etapa_recente": "Erro cr√≠tico de fluxo para o Advogado do R√©u.",
            "historico_completo": estado.get("historico_completo", []) + [{"etapa": "ERRO", "ator": ADVOGADO_REU, "documento": "Erro de fluxo irrecuper√°vel do Advogado R√©u."}],
            "id_processo": estado.get("id_processo", "ID_DESCONHECIDO"), # Preservar estado
            "retriever": estado.get("retriever"),
            "pontos_controvertidos_saneamento": estado.get("pontos_controvertidos_saneamento"),
            "manifestacao_autor_sem_provas": estado.get("manifestacao_autor_sem_provas", False),
            "manifestacao_reu_sem_provas": estado.get("manifestacao_reu_sem_provas", False),
            "etapa_a_ser_executada_neste_turno": "ERRO_FLUXO_IRRECUPERAVEL"
        }

    documento_gerado = f"Documento padr√£o para {ADVOGADO_REU} na etapa {etapa_atual_do_no} n√£o gerado."
    proximo_ator_logico = JUIZ # Default, ser√° sobrescrito pela l√≥gica da etapa
    retriever = estado["retriever"]
    id_processo = estado["id_processo"]
    historico_formatado = "\n".join([f"- Etapa: {item['etapa']}, Ator: {item['ator']}:\n  Documento: {item['documento'][:150]}..." for item in estado.get("historico_completo", [])])
    if not historico_formatado:
        historico_formatado = "Hist√≥rico processual n√£o dispon√≠vel."

    documento_relevante_anterior = estado.get("documento_gerado_na_etapa_recente", "Nenhum documento recente para an√°lise imediata.")
    
    query_fatos_caso = f"Resumo dos fatos e principais pontos do processo {id_processo} sob a perspectiva da defesa"
    docs_fatos_caso = retriever.get_relevant_documents(
        query=query_fatos_caso,
        filter={"source_type": "processo_atual", "process_id": id_processo}
    )
    contexto_fatos_caso = "\n".join([doc.page_content for doc in docs_fatos_caso]) if docs_fatos_caso else "Nenhum detalhe factual espec√≠fico do caso encontrado no RAG do processo_em_si para a defesa."
    print(f"[{ADVOGADO_REU}-{etapa_atual_do_no}] Contexto do caso (RAG): {contexto_fatos_caso[:200]}...")

    if etapa_atual_do_no == ETAPA_CONTESTACAO:
        peticao_inicial_autor = "Peti√ß√£o Inicial n√£o encontrada no hist√≥rico para contesta√ß√£o." 
        for item in reversed(estado.get("historico_completo", [])):
            if item["etapa"] == ETAPA_PETICAO_INICIAL and item["ator"] == ADVOGADO_AUTOR:
                peticao_inicial_autor = item["documento"]
                break
        
        docs_modelo_contestacao = retriever.get_relevant_documents(query="modelo de contesta√ß√£o c√≠vel completa", filter={"source_type": "modelo_peticao"})
        modelo_texto_guia = docs_modelo_contestacao[0].page_content if docs_modelo_contestacao else "ERRO RAG: Modelo de contesta√ß√£o n√£o encontrado."

        template_prompt = """
        Voc√™ √© um Advogado do R√©u experiente e est√° elaborando uma Contesta√ß√£o.
        **Processo ID:** {id_processo}
        **Tarefa:** Analisar a Peti√ß√£o Inicial do Autor e o despacho judicial, e elaborar uma Contesta√ß√£o completa, rebatendo os argumentos do autor, apresentando preliminares (se houver) e o m√©rito da defesa.

        **Contexto dos Fatos do Caso (do RAG, com foco na perspectiva da defesa):**
        {contexto_fatos_caso}

        **Despacho Judicial Recebido (ex: cita√ß√£o):**
        {despacho_judicial}
        
        **Peti√ß√£o Inicial do Autor (documento a ser contestado):**
        {peticao_inicial_autor}

        **Modelo/Guia de Contesta√ß√£o (use como refer√™ncia estrutural e de linguagem):**
        {modelo_texto_guia}
        
        **Hist√≥rico Processual at√© o momento:**
        {historico_formatado}
        ---
        Com base em todas as informa√ß√µes acima, redija a Contesta√ß√£o. Seja completo, claro e objetivo.
        Aten√ß√£o aos fatos espec√≠ficos do caso para a argumenta√ß√£o da defesa.
        Contesta√ß√£o:
        """
        chain = criar_prompt_e_chain(template_prompt)
        documento_gerado = chain.invoke({
            "id_processo": id_processo,
            "contexto_fatos_caso": contexto_fatos_caso,
            "despacho_judicial": documento_relevante_anterior, # Este √© o despacho do juiz recebendo a inicial
            "peticao_inicial_autor": peticao_inicial_autor,
            "modelo_texto_guia": modelo_texto_guia,
            "historico_formatado": historico_formatado
        })
        proximo_ator_logico = JUIZ # Ap√≥s contesta√ß√£o, juiz decide sobre saneamento (no fluxo simplificado). Poderia ser r√©plica do autor.

    elif etapa_atual_do_no == ETAPA_MANIFESTACAO_SEM_PROVAS_REU:
        manifestacao_autor_sem_provas_doc = documento_relevante_anterior # Manifesta√ß√£o do autor
        decisao_saneamento_texto = "Decis√£o de Saneamento n√£o encontrada no hist√≥rico recente." 
        if estado.get("pontos_controvertidos_saneamento"):
             decisao_saneamento_texto = f"Decis√£o de Saneamento anterior definiu: {estado['pontos_controvertidos_saneamento']}"
        else: 
            for item in reversed(estado.get("historico_completo", [])):
                if item["etapa"] == ETAPA_DECISAO_SANEAMENTO and item["ator"] == JUIZ:
                    decisao_saneamento_texto = item["documento"]
                    break

        docs_modelo_manifest = retriever.get_relevant_documents(query="modelo de peti√ß√£o ou manifesta√ß√£o declarando n√£o ter mais provas a produzir pela defesa", filter={"source_type": "modelo_peticao"})
        modelo_texto_guia = docs_modelo_manifest[0].page_content if docs_modelo_manifest else "ERRO RAG: Modelo de manifesta√ß√£o sem provas (R√©u) n√£o encontrado."

        template_prompt = """
        Voc√™ √© o Advogado do R√©u. O juiz proferiu Decis√£o de Saneamento e o Autor j√° se manifestou sobre n√£o ter mais provas.
        **Processo ID:** {id_processo}
        **Tarefa:** Elaborar uma peti√ß√£o informando que o R√©u tamb√©m n√£o possui mais provas a produzir, ou especificando as √∫ltimas provas, se houver. Assumindo que n√£o h√° mais provas, requerer o julgamento do feito.

        **Contexto dos Fatos do Caso (do RAG, com foco na perspectiva da defesa):**
        {contexto_fatos_caso}

        **Decis√£o de Saneamento proferida pelo Juiz:**
        {decisao_saneamento_texto}
        
        **Manifesta√ß√£o do Autor sobre n√£o ter mais provas:**
        {manifestacao_autor_sem_provas_doc}

        **Modelo/Guia de Manifesta√ß√£o (use como refer√™ncia):**
        {modelo_texto_guia}
        
        **Hist√≥rico Processual at√© o momento:**
        {historico_formatado}
        ---
        Redija a Peti√ß√£o de Manifesta√ß√£o do R√©u.
        Manifesta√ß√£o do R√©u:
        """
        chain = criar_prompt_e_chain(template_prompt)
        documento_gerado = chain.invoke({
            "id_processo": id_processo,
            "contexto_fatos_caso": contexto_fatos_caso,
            "decisao_saneamento_texto": decisao_saneamento_texto,
            "manifestacao_autor_sem_provas_doc": manifestacao_autor_sem_provas_doc,
            "modelo_texto_guia": modelo_texto_guia,
            "historico_formatado": historico_formatado
        })
        proximo_ator_logico = JUIZ 

    else:
        print(f"AVISO: L√≥gica para etapa '{etapa_atual_do_no}' do {ADVOGADO_REU} n√£o implementada completamente.")
        documento_gerado = f"Conte√∫do para {ADVOGADO_REU} na etapa {etapa_atual_do_no} n√£o foi gerado pela l√≥gica espec√≠fica."
        proximo_ator_logico = JUIZ 

    print(f"[{ADVOGADO_REU}-{etapa_atual_do_no}] Documento Gerado (trecho): {documento_gerado[:250]}...")
    
    novo_historico_item = {"etapa": etapa_atual_do_no, "ator": ADVOGADO_REU, "documento": documento_gerado}
    historico_atualizado = estado.get("historico_completo", []) + [novo_historico_item]

    return {
        "nome_do_ultimo_no_executado": ADVOGADO_REU,
        "etapa_concluida_pelo_ultimo_no": etapa_atual_do_no,
        "proximo_ator_sugerido_pelo_ultimo_no": proximo_ator_logico,
        "documento_gerado_na_etapa_recente": documento_gerado,
        "historico_completo": historico_atualizado,
        "pontos_controvertidos_saneamento": estado.get("pontos_controvertidos_saneamento"), 
        "manifestacao_autor_sem_provas": estado.get("manifestacao_autor_sem_provas", False), 
        "manifestacao_reu_sem_provas": estado.get("manifestacao_reu_sem_provas", False) or (etapa_atual_do_no == ETAPA_MANIFESTACAO_SEM_PROVAS_REU),
        "id_processo": estado["id_processo"],
        "retriever": estado["retriever"],
        "etapa_a_ser_executada_neste_turno": etapa_atual_do_no,
    }

# --- 8. Constru√ß√£o do Grafo LangGraph ---
workflow = StateGraph(EstadoProcessual)

workflow.add_node(ADVOGADO_AUTOR, agente_advogado_autor)
workflow.add_node(JUIZ, agente_juiz)
workflow.add_node(ADVOGADO_REU, agente_advogado_reu)

workflow.set_entry_point(ADVOGADO_AUTOR)

roteamento_mapa_edges = {
    ADVOGADO_AUTOR: ADVOGADO_AUTOR,
    JUIZ: JUIZ,
    ADVOGADO_REU: ADVOGADO_REU,
    END: END
}

workflow.add_conditional_edges(ADVOGADO_AUTOR, decidir_proximo_no_do_grafo, roteamento_mapa_edges)
workflow.add_conditional_edges(JUIZ, decidir_proximo_no_do_grafo, roteamento_mapa_edges)
workflow.add_conditional_edges(ADVOGADO_REU, decidir_proximo_no_do_grafo, roteamento_mapa_edges)

app = workflow.compile()

# --- 9. Execu√ß√£o da Simula√ß√£o com Streamlit ---
if __name__ == "__main__":
    st.set_page_config(layout="wide")
    st.title("Simula√ß√£o Jur√≠dica Avan√ßada")
    st.subheader("Rito Ordin√°rio do CPC")

    # Inicializar session_state para visualiza√ß√£o de documentos
    if 'doc_visualizado' not in st.session_state:
        st.session_state.doc_visualizado = None
        st.session_state.doc_visualizado_titulo = ""
    if 'expand_all_steps' not in st.session_state:
        st.session_state.expand_all_steps = True
    if 'expand_all_history' not in st.session_state: # Para os expanders detalhados
        st.session_state.expand_all_history = False

    id_processo_simulado = st.text_input("ID do Processo:", "caso_001")
    arquivo_processo_upload = st.file_uploader("Carregar Arquivo do Processo (.docx):", type=["docx"])

    # Placeholder para o documento completo (ser√° usado pela timeline e pelos expanders)
    doc_completo_placeholder = st.empty()

    if arquivo_processo_upload is not None:
        # ... (l√≥gica de upload e inicializa√ß√£o do retriever como antes) ...
        nome_arquivo_temporario = f"temp_{id_processo_simulado}_{arquivo_processo_upload.name}"
        caminho_temp_salvo = os.path.join(PATH_PROCESSO_EM_SI, nome_arquivo_temporario)
        
        os.makedirs(PATH_PROCESSO_EM_SI, exist_ok=True)
        
        with open(caminho_temp_salvo, "wb") as f:
            f.write(arquivo_processo_upload.read())

        st.markdown(f"--- INICIANDO SIMULA√á√ÉO PARA O PROCESSO: **{id_processo_simulado}** ---")

        retriever_do_caso = None
        try:
            with st.spinner("Inicializando sistema RAG e carregando documentos..."):
                retriever_do_caso = criar_ou_carregar_retriever(id_processo_simulado, nome_arquivo_temporario)
            st.success("Sistema RAG inicializado com sucesso.")
        except Exception as e:
            st.error(f"ERRO FATAL: Falha cr√≠tica ao inicializar o sistema RAG. Detalhe: {e}")
            if os.path.exists(caminho_temp_salvo):
                os.remove(caminho_temp_salvo) 
            st.stop()

        estado_inicial = EstadoProcessual(
            id_processo=id_processo_simulado,
            retriever=retriever_do_caso,
            nome_do_ultimo_no_executado=None,
            etapa_concluida_pelo_ultimo_no=None,
            proximo_ator_sugerido_pelo_ultimo_no=ADVOGADO_AUTOR,
            documento_gerado_na_etapa_recente=None,
            historico_completo=[],
            pontos_controvertidos_saneamento=None,
            manifestacao_autor_sem_provas=False,
            manifestacao_reu_sem_provas=False,
            etapa_a_ser_executada_neste_turno=""
        )
        # ... (l√≥gica da execu√ß√£o da simula√ß√£o com app.stream e st.expander para os passos como antes) ...
        st.subheader("Acompanhamento da Simula√ß√£o:")
        if st.button("Alternar Expans√£o dos Passos da Execu√ß√£o"):
            st.session_state.expand_all_steps = not st.session_state.expand_all_steps
        progress_bar = st.progress(0)
        steps_container = st.container()
        max_passos_simulacao = 15 
        passo_atual_simulacao = 0
        estado_final_simulacao = None
        # ... (Loop app.stream como na vers√£o anterior) ...
        try:
            for s in app.stream(input=estado_inicial, config={"recursion_limit": max_passos_simulacao}):
                passo_atual_simulacao += 1
                num_total_etapas_estimadas = len(mapa_tarefa_no_atual) + 1
                progress_value = min(100, int((passo_atual_simulacao / num_total_etapas_estimadas) * 100))
                progress_bar.progress(progress_value)

                if not isinstance(s, dict) or not s:
                    msg = f"Erro: Stream retornou valor inesperado: {s}. Encerrando."
                    steps_container.error(msg)
                    break

                nome_do_no_executado = list(s.keys())[0]
                estado_parcial_apos_no = s[nome_do_no_executado]
                estado_final_simulacao = estado_parcial_apos_no

                etapa_concluida_log = estado_parcial_apos_no.get('etapa_concluida_pelo_ultimo_no', 'N/A')
                doc_gerado_completo = str(estado_parcial_apos_no.get('documento_gerado_na_etapa_recente', ''))
                prox_ator_sug_log = estado_parcial_apos_no.get('proximo_ator_sugerido_pelo_ultimo_no', 'N/A')
                
                expander_title = f"Passo {passo_atual_simulacao}: {nome_do_no_executado} concluiu '{etapa_concluida_log}'"
                if nome_do_no_executado == END:
                     expander_title = f"Passo {passo_atual_simulacao}: Fim da Simula√ß√£o"
                
                with steps_container.expander(expander_title, expanded=st.session_state.expand_all_steps):
                    st.markdown(f"**N√≥ Executado:** `{nome_do_no_executado}`")
                    st.markdown(f"**Etapa Conclu√≠da:** `{etapa_concluida_log}`")
                    if etapa_concluida_log != "ERRO_FLUXO_IRRECUPERAVEL" and doc_gerado_completo:
                        st.text_area("Documento Gerado:", value=doc_gerado_completo, height=200, key=f"doc_step_{passo_atual_simulacao}", disabled=True)
                    elif doc_gerado_completo:
                        st.error(f"Detalhe do Erro/Documento: {doc_gerado_completo}")
                    st.markdown(f"**Pr√≥ximo Ator Sugerido:** `{prox_ator_sug_log}`")

                if nome_do_no_executado == END or prox_ator_sug_log == ETAPA_FIM_PROCESSO:
                    steps_container.success("Fluxo da simula√ß√£o atingiu o n√≥ FINAL ou etapa de fim.")
                    progress_bar.progress(100)
                    break
                if passo_atual_simulacao >= max_passos_simulacao:
                    steps_container.warning(f"Simula√ß√£o atingiu o limite m√°ximo de {max_passos_simulacao} passos.")
                    break
        except Exception as e:
            st.error(f"ERRO INESPERADO DURANTE A EXECU√á√ÉO DA SIMULA√á√ÉO: {e}")
            import traceback
            st.text_area("Stack Trace do Erro:", traceback.format_exc(), height=300)
        finally:
            if os.path.exists(caminho_temp_salvo):
                os.remove(caminho_temp_salvo)
                print(f"[Main] Arquivo tempor√°rio '{caminho_temp_salvo}' removido.")
            progress_bar.empty()

        st.markdown("---")
        st.subheader("Linha do Tempo Interativa do Processo")

        if estado_final_simulacao and estado_final_simulacao.get("historico_completo"):
            historico = estado_final_simulacao["historico_completo"]
            
            # Mapeamento de √≠cones (Unicode emojis)
            icon_map = {
                ADVOGADO_AUTOR: "üôã‚Äç‚ôÇÔ∏è", # Pessoa levantando a m√£o (autor)
                JUIZ: "‚öñÔ∏è",          # Balan√ßa da justi√ßa
                ADVOGADO_REU: "üôã‚Äç‚ôÄÔ∏è", # Pessoa levantando a m√£o (r√©u - outra figura)
                ETAPA_PETICAO_INICIAL: "üìÑ",
                ETAPA_DESPACHO_RECEBENDO_INICIAL: "‚û°Ô∏è",
                ETAPA_CONTESTACAO: " ÿØŸÅÿßÿπ ", # Defesa em √°rabe (exemplo visual) ou "üõ°Ô∏è",
                ETAPA_DECISAO_SANEAMENTO: "üõ†Ô∏è",
                ETAPA_MANIFESTACAO_SEM_PROVAS_AUTOR: "üó£Ô∏è",
                ETAPA_MANIFESTACAO_SEM_PROVAS_REU: "üó£Ô∏è",
                ETAPA_SENTENCA: "üèÅ",
                "DEFAULT_ACTOR": "üë§",
                "DEFAULT_ETAPA": "üìë"
            }

            # Criar colunas para a linha do tempo. O n√∫mero de colunas √© o n√∫mero de etapas.
            # Se for muito grande, o Streamlit vai empilhar.
            # Para um visual mais controlado, poder√≠amos limitar o n√∫mero de itens por linha
            # ou usar um container com overflow CSS (mais complexo).
            # Por simplicidade, vamos usar colunas diretas.
            
            num_etapas = len(historico)
            cols = st.columns(num_etapas)

            for i, item_hist in enumerate(historico):
                ator_hist = item_hist.get('ator', 'N/A')
                etapa_hist = item_hist.get('etapa', 'N/A')
                doc_completo_hist = str(item_hist.get('documento', 'N/A'))
                
                ator_icon = icon_map.get(ator_hist, icon_map["DEFAULT_ACTOR"])
                etapa_icon = icon_map.get(etapa_hist, icon_map["DEFAULT_ETAPA"])

                with cols[i]:
                    # Exibir o √≠cone do ator e da etapa de forma proeminente
                    st.markdown(f"<div style='text-align: center; font-size: 24px;'>{ator_icon}{etapa_icon}</div>", unsafe_allow_html=True)
                    # Nome do ator e etapa abaixo dos √≠cones
                    st.markdown(f"<p style='text-align: center; font-size: 12px; margin-bottom: 5px;'><b>{ator_hist}</b><br>{etapa_hist}</p>", unsafe_allow_html=True)
                    
                    # Bot√£o para ver o documento
                    if st.button(f"Doc {i+1}", key=f"btn_timeline_{i}", help=f"Ver documento: {ator_hist} - {etapa_hist}"):
                        st.session_state.doc_visualizado = doc_completo_hist
                        st.session_state.doc_visualizado_titulo = f"Documento (Etapa {i+1} da Linha do Tempo): {ator_hist} - {etapa_hist}"
                        # st.rerun() # Geralmente n√£o necess√°rio se o placeholder estiver fora do loop de colunas

                # Adicionar uma "seta" ou conector entre as colunas, exceto para a √∫ltima
                # Isso √© dif√≠cil de fazer de forma robusta com st.columns diretamente.
                # Poder√≠amos tentar com st.markdown entre as colunas, mas o alinhamento √© complexo.
                # Para esta vers√£o, omitiremos as setas conectoras complexas entre colunas.
                # Uma linha simples abaixo da "faixa" da timeline pode ser uma op√ß√£o.
            
            if num_etapas > 0:
                 st.markdown("---") # Linha separadora ap√≥s a timeline

        else:
            st.warning("Nenhum hist√≥rico completo dispon√≠vel para exibir na linha do tempo.")

        # Exibi√ß√£o do documento completo selecionado (fora do loop do hist√≥rico)
        # Este placeholder √© crucial e deve estar FORA de qualquer loop de colunas ou expanders.
        if st.session_state.doc_visualizado:
            with doc_completo_placeholder.container():
                st.subheader(st.session_state.doc_visualizado_titulo)
                st.text_area("Conte√∫do do Documento:", st.session_state.doc_visualizado, height=400, key="doc_view_timeline_area")
                if st.button("Fechar Visualiza√ß√£o do Documento", key="close_doc_view_timeline_btn"):
                    st.session_state.doc_visualizado = None
                    st.session_state.doc_visualizado_titulo = ""
                    st.rerun()
        
        st.markdown("---")
        # Manter a se√ß√£o de Hist√≥rico Detalhado com expanders se ainda for √∫til
        st.subheader("Hist√≥rico Detalhado (Conte√∫do das Etapas):")
        # (O c√≥digo dos expanders do hist√≥rico detalhado pode permanecer aqui, como antes)
        if estado_final_simulacao and estado_final_simulacao.get("historico_completo"):
            if st.button("Alternar Expans√£o dos Itens do Hist√≥rico Detalhado"):
                st.session_state.expand_all_history = not st.session_state.expand_all_history
            for i, item_hist in enumerate(estado_final_simulacao["historico_completo"]):
                ator_hist = item_hist.get('ator', 'N/A')
                etapa_hist = item_hist.get('etapa', 'N/A')
                doc_completo_hist = str(item_hist.get('documento', 'N/A'))
                with st.expander(f"{i+1}. Ator: {ator_hist} | Etapa: {etapa_hist}", expanded=st.session_state.expand_all_history):
                    # ... (conte√∫do do expander como antes, mas o bot√£o de ver documento aqui pode ser removido se a timeline for suficiente)
                    st.text_area(f"Documento Gerado (Detalhe {i+1}):", value=doc_completo_hist, height=150, key=f"doc_hist_detail_{i}", disabled=True)

        st.markdown("--- FIM DA SIMULA√á√ÉO ---")
        print("\n[Main] Execu√ß√£o da simula√ß√£o Streamlit conclu√≠da.")

    else:
        st.info("Aguardando upload do arquivo do processo para iniciar a simula√ß√£o.")